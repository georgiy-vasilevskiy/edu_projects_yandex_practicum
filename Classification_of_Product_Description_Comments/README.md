<table border="1" width="100%" cellpadding="40"><tbody>
  <tr>
    <td width="20%" align="center">
      <img src="https://github.com/georgiy-vasilevskiy/edu_projects_yandex_practicum/blob/main/pic/Classification_of_Product_Description_Comments.png" height="150" width="150">
    </td>
    <td valign="top">
      <h3>Классификация комментариев к описаниям товаров интернет-магазина</h3>
      <br><i>Classification of Product Description Comments</i>
    </td>
  </tr>
  <tr>
    <td>
      <a title="Использовать для просмотра Jupyter nbviewer" href="https://nbviewer.org/github/georgiy-vasilevskiy/edu_projects_yandex_practicum/blob/main/Classification_of_Product_Description_Comments/Classification_of_Product_Description_Comments.ipynb">
        <img src="https://img.shields.io/badge/Смотреть-ipynb-F37626">
      </a>
      <a title="Использовать для просмотра GitHub & BitBucket HTML Preview" href="https://htmlpreview.github.io/?https://github.com/georgiy-vasilevskiy/edu_projects_yandex_practicum/blob/main/Classification_of_Product_Description_Comments/Classification_of_Product_Description_Comments.html">
        <img src="https://img.shields.io/badge/Смотреть-html-54B231">
      </a>
    </td>
    <td>
      <b>Ключевые слова:</b> бинарная классификация, токенизация, лемматизация, векторизация, табличные данные, обучение алгоритмов, взвешивание классов, N-граммы, биграммы, триграммы, F1-мера, валидация
    </td>
  </tr>
</tbody></table>

<p align='justify'>Интернет-магазин предоставляет своим пользователям возможность оставлять комментарии к описаниям товаров. Комментарии могут содержать отзывы пользователей, их вопросы, рекомендации, а также другую информацию, помогающую остальным покупателям быть более информированными при выборе товара и помогающую им принять взвешенное решение о его покупке. Такие комментарии могут быть как позитивными, так и негативными.</p>

<p align='justify'>Является ли комментарий токсичным, зависит от его содержания и от того, как он воспринимается другими пользователями. Комментарий может быть токсичным, если он содержит оскорбления, угрозы, ненормативную лексику или другой негативный контент. Их необходимо обнаруживать и отправлять на модерацию.</p>

<p align='justify'>Основная идея проекта &mdash; используя размеченные данные, научиться автоматически обнаруживать тексты к описаниям товаров, которые содержат негативный контент, и отправлять их на модерацию.</p>

<p align='justify'><b>Исходные данные:</b> размеченные данные, содержащие тексты комментариев с разметкой об их токсичности.</p>

1 файл в формате CSV: 159 292 записи $\times$ 3 признака.

**Цель проекта:** построить модель машинного обучения, которая наилучшим образом классифицирует комментарии на позитивные и негативные.

**Инструменты:** python, pandas, os, re, spacy, nltk, matplotlib, scikit-learn, catboost, lightgbm.

**Основные этапы проекта:**
- <b>предобработка данных:</b><p align='justify'>удалены небуквенные символы; выполнена токенизация и лемматизация текстов; обработаны пропуски (записи удалены); обработаны дубликаты (записи удалены);
- <b>построение моделей:</b><p align='justify'>подготовлены данные для обучения &mdash; в данных выделены тренировочная, валидационная и тестовая выборки (3 : 1 : 1); оценка качества обученных моделей проведена методом валидации; критерий оценки качества моделей — максимальное значение F1-меры, полученное в результате проведения валидации (пороговое значение F1-меры установлено равным 0,75); для учёта дисбаланса классов при обучении алгоритмов использовано взвешивание классов.<br><br>Данные подавались алгоритмам через конвейер (Pipeline), в котором предварительно проводилась векторизация текстов (TfidfVectorizer) с учётом стоп-слов. Подбор параметров моделей производился через случайный поиск по сетке значений гиперпараметров (RandomizedSearchCV). Были обучены линейные модели: логистическая регрессия, классификаторы с использованием гребневой регрессии, стохастического градиентного спуска, классификатор на основе метода опорных векторов; а также модели на основе деревьев решений: дерево решений, градиентные бустинги LightGBM, CatBoost; кроме того, была обучена простая модель, предсказываюшая значение меньшего класса. Для обучения линейных моделей и модели на основе метода опорных векторов дополнительно использованы N-граммы: биграммы и триграммы.</p>

<p align='justify'><b>Результат исследования:</b> наилучшие показатели качества продемонстрировала модель классификатора, использующая алгоритм стохастического градиентного спуска с параметрами &mdash; альфа: 0,00001, начальная скорость обучения: 1, порог остановки обучения: 0,001, обученный на тексте, векторизованном методом TF-IDF, с включением в обучающий набор биграмм и триграмм, с зафиксированной псевдослучайностью (random_state=1).Значение F1-меры, полученное в результате проведения валидации, составило 0,754. Значение F1-меры на тестовой выборке равно 0,782.</p>

<p align='center'><img src='https://github.com/georgiy-vasilevskiy/edu_projects_yandex_practicum/blob/main/pic/terminator.png' width=75></p>
